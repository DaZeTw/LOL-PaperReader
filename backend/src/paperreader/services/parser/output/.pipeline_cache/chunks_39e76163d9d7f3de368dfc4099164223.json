[
  {
    "doc_id": "2303.14334v2",
    "title": "Marti A. Hearst ùõΩ Daniel S. Weld ùõº",
    "page": 1,
    "text": "ùõº Allen Institute for AI ùúî University of Washington\nùõΩ University of California, Berkeley\nùúì University of Pennsylvania\nùúí Carnegie Mellon University ùúè Massachusetts Institute of Technology ùúÖ KAIST\nùúÑ Johns Hopkins University ùúê University of Minnesota ùúé University of California, San Diego\nùúå Microsoft Research",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "ABSTRACT",
    "page": 1,
    "text": "Scholarly publications are key to the transfer of knowledge from\nscholars to others. However, research papers are information-dense,\nand as the volume of the scientific literature grows, the need for new\ntechnology to support the reading process grows. In contrast to the\nprocess of finding papers, which has been transformed by Internet\ntechnology, the experience of reading research papers has changed\nlittle in decades. The PDF format for sharing papers is widely used\ndue to its portability, but it has significant downsides including:\nstatic content, poor accessibility for low-vision readers, and diffi-\nculty reading on mobile devices. This paper explores the question\n‚ÄúCan recent advances in AI and HCI power intelligent, interactive,\nand accessible reading interfaces‚Äîeven for legacy PDFs?‚Äù We de-\nscribe the Semantic Reader Project, a collaborative effort across\nmultiple institutions to explore automatic creation of dynamic read-\ning interfaces for research papers. Through this project, we‚Äôve de-\nveloped ten research prototype interfaces and conducted usability\nstudies with 300+ participants and real-world users showing im-\nproved reading experiences for scholars. We‚Äôve also released",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "ABSTRACT",
    "page": 1,
    "text": "we‚Äôve de-\nveloped ten research prototype interfaces and conducted usability\nstudies with 300+ participants and real-world users showing im-\nproved reading experiences for scholars. We‚Äôve also released a pro-\nduction research paper reader that will incorporate novel features\nas they mature. We structure this paper around challenges scholars\nand the public face when reading research papers‚Äîdiscovery, effi-\nciency, comprehension, synthesis, and accessibility‚Äîand present\nan overview of our progress and remaining open challenges.",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "INTRODUCTION",
    "page": 1,
    "text": "The exponential growth of scientific publication [ 7 , 8 ] and increas-\ning interdisciplinary nature of scientific progress [ 71 , 94 ] makes",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "INTRODUCTION",
    "page": 1,
    "text": "‚àó [ .......\nClick...to.......\nopen....\nin.....\nthe ............\nSemantic..........\nReader ]\n[ .............\nDownload.....\nthe ..........\nversion.......\nwith .........\nalt-text ]",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "INTRODUCTION",
    "page": 1,
    "text": "it increasingly hard for scholars to keep up with the latest devel-\nopments. Academic search engines, such as Google Scholar and\nSemantic Scholar help scholars discover research papers. Auto-\nmated summarization for research papers [ 11 ] helps scholars triage\nbetween research papers. But when it comes to actually reading\nresearch papers, the process, based on a static PDF format, has\nremained largely unchanged for many decades. This is a problem\nbecause digesting technical research papers is difficult [2, 5].\nIn contrast, interactive and personalized documents have seen\nsignificant adoption in domains outside of academic research. For\nexample, news websites such as the New York Times often present\ninteractive articles with explorable visualizations that allow read-\ners to understand complex data in a personalized way. E-readers,\nsuch as the Kindle, provide in-situ context to help readers better\ncomprehend complex documents, showing inline term definitions\nand tracking occurrence of characters in a long novel. While prior\nwork has focused on authoring support tools [ 21 , 22 , 54 ] that can\nreduce effort in creating interactive scientific documents [ 34 , 38 ],\nthey have not seen w",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "INTRODUCTION",
    "page": 1,
    "text": "aracters in a long novel. While prior\nwork has focused on authoring support tools [ 21 , 22 , 54 ] that can\nreduce effort in creating interactive scientific documents [ 34 , 38 ],\nthey have not seen widespread adoption due to a lack of incentive\nstructure [ 27 ]. Furthermore, millions of research papers are locked\nin the rigid and static PDF format, whose low-level syntax makes\nit extremely difficult for systems to access semantic content, aug-\nment interactivity, or even provide basic reading functionality for\nassistive tools like screen readers [6].\nFortunately, recent work on layout-aware document parsing [ 39 ,\n86 , 104 ] and large language models [ 4 , 10 , 83 ] show promise for\naccessing the content of PDF documents, and building systems that\ncan better understand their semantics. This raises an exciting chal-\nlenge: Can we create intelligent, interactive, and accessible reading\ninterfaces for research papers, even atop existing PDFs?",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "UNLOCKING CITATIONS FOR DISCOVERY",
    "page": 3,
    "text": "Scholars use many methods to discover relevant research papers\nto read, including search engines, word of mouth, and browsing\nfamiliar venues. However, once they find one research paper, it‚Äôs\nespecially common for scholars to use its references and citations\nto further expand their knowledge of a research area. This behavior,\nsometimes referred to as forward/backward chaining or footnote\nchasing , is ubiquitous and has been observed across many schol-\narly disciplines [ 74 ]. Supporting this, one popular feature in the\nSemantic Reader 1 is in-situ Paper Cards that pop up when readers\nclick on an inline citation, dramatically reducing the interaction\ncost caused by jumping back-and-forth between inline citations\nand their corresponding references at the end of a research paper\n(Figure 1). Despite this affordance, during literature reviews, read-\ners may still be overwhelmed trying to make sense of the tens to\nhundreds of inline citations in each paper [ 15 , 24 , 77 ]. Conversely,\nwhen reading a given paper, a reader cannot see relevant follow-on\nresearch papers that cited the current paper. Here we discuss how\ninteractive reading interfaces can help scholars more effectively\nexplor",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "UNLOCKING CITATIONS FOR DISCOVERY",
    "page": 3,
    "text": "reading a given paper, a reader cannot see relevant follow-on\nresearch papers that cited the current paper. Here we discuss how\ninteractive reading interfaces can help scholars more effectively\nexplore citations to important relevant work in both directions with\ntwo systems called CiteSee [15] and CiteRead [82].",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "Augmenting Citations with CiteSee",
    "page": 3,
    "text": "While most prior work on supporting research paper discovery has\nfocused on developing bespoke interfaces of recommender systems\nor visualizations based on paper contents [ 78 , 89 ], the citation graph\n[ 16 , 30 , 32 , 40 , 63 , 80 , 103 ], or a combination of the two [ 20 , 96 ],\nresearch paper discovery via inline citations in a reading interface is\nimportant but under-explored. One study estimates that reading and",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "Augmenting Citations with CiteSee",
    "page": 3,
    "text": "exploring inline citations accounts for around one in five research\npaper discoveries during active research [ 49 ]. However, while all\ninline citations are relevant to the current research paper, it is likely\nthat some are more relevant to the current reader than others. For\nexample, a reader reading papers about aspect extraction of online\nproduct reviews to learn more about natural language processing\ntechniques would be less interested in citations to research papers\naround e-commerce and marketing . In addition, citations to the same\nresearch papers often have different surface forms across papers\n(i.e., reference numbers), making it all the more difficult for readers\nto keep track of all the inline citations they should explore or have\nalready explored during literature reviews.\nTo address this, CiteSee provides a personalized research paper\nreading experience by automatically identifying and resolving in-\nline citations in PDFs to research paper entities in our academic\ngraph [ 50 ], and visually augmenting inline citations based on their\nconnections to the current reader. First, CiteSee leverages a reader‚Äôs\nreading behavior and history as a way to capture their short-term\na",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "Augmenting Citations with CiteSee",
    "page": 3,
    "text": "50 ], and visually augmenting inline citations based on their\nconnections to the current reader. First, CiteSee leverages a reader‚Äôs\nreading behavior and history as a way to capture their short-term\nand fluid interests during literature reviews. Using this signal, Cite-\nSee scores and highlights inline citations to help the reader triage\nthem and discover prior work that are likely relevant to their liter-\nature review topics (Figure 2). Second, CiteSee leverages research\npapers saved in the reader‚Äôs Semantic Scholar paper library and the\nreader‚Äôs publication record [ 50 ] to understand their longer-term\nresearch interests. Using this signal, CiteSee changes the colors of\nthe inline citations to familiar papers so that the reader can both\nbetter contextualize the current paper and keep track of citations\nto papers they have already explored. In addition, CiteSee also\nhelps readers better make sense of the cited papers by showing\nhow they connect to a reader‚Äôs previous activities; for example,\nshowing which library folders they were saved under or the cit-\ning sentences from a familiar research paper (Figure 2). Based on\nlab and field studies, CiteSee showed promise that providing v",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "Augmenting Citations with CiteSee",
    "page": 3,
    "text": "xample,\nshowing which library folders they were saved under or the cit-\ning sentences from a familiar research paper (Figure 2). Based on\nlab and field studies, CiteSee showed promise that providing vi-\nsual augmentation and personalized context around inline citations\nin an interactive reading environment can allow readers to more\neffectively discover relevant prior work and keep track of their\nexploration during real-world literature review tasks.",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "Exploring Future Work with CiteRead",
    "page": 3,
    "text": "While augmenting inline citations helps readers to triage them,\nmany relevant research papers are not cited in a research paper in\nthe first place, for example, because they were published afterwards.\nCiteRead is a novel reading interface that helps readers discover\nhow follow-on work has built on or engaged with the research\npaper [ 82 ]. Much like social document annotation systems [ 109 ],\nCiteRead annotates text in the paper with margin notes containing\nrelevant commentary from citing papers [ 70 ], thereby helping the\nreader to become aware of the citing paper and its connection. In\norder to produce these annotations automatically, CiteRead first\nfilters citing research papers for ones that are most relevant to the\nreader using a trained model atop a number of features representing\ncitational discourse and textual similarity, i.e. from scientific paper\nembeddings [ 20 ]. CiteRead then localizes citing papers to partic-\nular spans of text in the paper being read, and extracts relevant\ninformation from the citing paper. Figure 3 shows a research paper\nannotated with this information from citing papers. Localization is",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "NAVIGATION AND EFFICIENT READING",
    "page": 4,
    "text": "An important part of reading a paper is knowing what and where\nto read. Scholars often read papers non-linearly; they might return\nto a previously-read passage to recall some information, or jump\nforward to a different section of the paper (or to another paper) to\nsatisfy an information need before jumping back. While jumping\ncan help scholars orient their reading to sections of interest, it\ncan also be a distraction by causing readers to constantly switch\ncontexts. Non-linear navigation can be especially burdensome when\nthe reader is interested in a particular type of information (e.g.,\nskimming a paper for the main results), but doesn‚Äôt know precisely\nwhere to find it within the paper. In this section we discuss two\nsystems, Scim [ 28 ] and Ocean [ 75 ], which demonstrate different\napproaches to helping readers navigate efficiently through a paper\ntoward high-value, relevant information.",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "Guided Reading with Scim",
    "page": 4,
    "text": "Scholarly reading can be considered a type of sensemaking rep-\nresented as a continuous interplay between two processes: infor-\nmation foraging in which readers identify relevant paper content,\nand comprehension in which readers attempt to integrate the new\ninformation into their working model of the paper and with rel-\nevant prior knowledge [ 79 , 84 ]. Distinguishing between relevant\nand irrelevant content could help facilitate efficient reading. Paper",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "Guided Reading with Scim",
    "page": 4,
    "text": "Figure 4: The Scim [28] interface guides reader attention\nusing color highlights corresponding to discourse facets. A\nsidebar allows users to toggle facets on/off. Clicking a color-\ncoded snippet scrolls the reader to the relevant passage.",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "Guided Reading with Scim",
    "page": 4,
    "text": "abstracts offer one such separation, in essence an author-crafted\ndetermination of relevant content. However, static paper abstracts\ncan leave readers to desire additional details that then require them\nto skim the paper itself.\nScim [ 28 ] addresses this problem via an augmented reading\ninterface designed to guide readers‚Äô attention using automatically-\ncreated in-situ faceted highlights (Figure 4). Though prior work\nhas explored highlighting as a visual cue for guiding reader atten-\ntion [ 18 , 102 , 105 ], the efficacy for reading of scholarly text is less\nwell-understood. Scim investigated the following design goals for\nintelligent highlights in scholarly reading: highlights should be\n(1) evenly-distributed throughout a paper, (2) have just the right\ndensity (too few highlights will present the guise of an inept tool,\nand too many will slow a reader down), and (3) highlight several\nkey categories of information in the paper. Because readers often\nskim for common types of information, Scim uses a pretrained lan-\nguage model [ 99 ] to classify salient sentences within papers into\none of four information facets: research objectives, novel aspects\nof the research, methodology, and ",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "Guided Reading with Scim",
    "page": 4,
    "text": "n, Scim uses a pretrained lan-\nguage model [ 99 ] to classify salient sentences within papers into\none of four information facets: research objectives, novel aspects\nof the research, methodology, and results, coupled with heuristics\nthat ensure an even distribution of highlights. Usability studies\nof Scim have shown these highlights can reduce the time it takes\nreaders to find specific information within a paper. Readers found\nScim particularly useful when skimming text-dense papers, or for\npapers that fell outside their area of expertise. Moreover, readers\nlearned to use both Scim‚Äôs inline highlights and a sidebar summary\nof highlights to augment their existing reading strategies.",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "Reader-Sourced Hyperlinks with Ocean",
    "page": 4,
    "text": "The task of navigating between sections and retrieving content\ncan be particularly challenging for blind and low-vision readers\ndue to limitations in auditory information access or small view-\nports under high magnification [ 90 ]. Even when related content\nis linked, a small viewport can make navigation difficult and ne-\ncessitate scrolling [ 75 ]. Most existing tools such as for auditory\nskimming [ 45 ] do not address such challenges associated with low-\nvision and magnification.",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "COMPREHENSION",
    "page": 5,
    "text": "Could an augmented reading application help readers understand\na paper by reducing the cognitive load associated with reading a\npaper? In this section, we discuss several ways in which interac-\ntive reading aids can help a reader understand a paper with less\nwork through three systems: ScholarPhi [ 33 ], PaperPlain [ 1 ] and\nPapeo [ 92 ]. In particular, papers can be augmented with definitions\nof terms and symbols, provide plain-language summaries of paper\npassages, and connect readers with alternative forms of expres-\nsion (for instance, video clips of research talks) that offer more\napproachable explanations of the paper‚Äôs content.",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "ScholarPhi",
    "page": 5,
    "text": "Understanding a paper requires understanding its vocabulary. How-\never, this is by no means an easy task‚Äîa typical paper may contain\ndozens of acronyms, symbols, and invented terms. And often, these\nterms appear without accompanying definitions [ 69 ]. How can we\ndesign interactive aids that present definitions of terms when and\nwhere readers most need them? ScholarPhi [ 33 ] takes as its basis\nthe term gloss‚Äîan extension to a reading interface that shows a\nreader an explanation of a phrase when they click it. Glosses ap-\npeared in early research interfaces for reading hypertext [ 107 ] and",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "ScholarPhi",
    "page": 5,
    "text": "Figure 5: ScholarPhi [33] shows definitions of terms and\nsymbols in pop-up tooltips. When a reader selects a formula,\nall known definitions of symbols are shown simultaneously.\nTo let readers select nested symbols (e.g., ‚Äú ‚Ñé ‚Äù in ‚Äú ùëâ ( ùëó )\n‚Ñé\n‚Äù), Schol-\narPhi supports ‚Äúdrill-down‚Äù subsymbol selection.",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "ScholarPhi",
    "page": 5,
    "text": "Figure 6: Paper Plain [1] provides in-situ plain language\nsummaries of passages called ‚Äúgists‚Äù to help readers who are\noverwhelmed by complex textual passages. Readers access\ngists by clicking a flag next to a section header. These gists\nare generated by large language models.",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "ScholarPhi",
    "page": 5,
    "text": "have since become part of widely-used reading interfaces including\nWikipedia and Kindle.\nThat said, familiar gloss designs do not work well for scientific\npapers, where glosses run the risk of distracting readers, terms have\nmultiple meanings, and phrases (specifically math symbols) are dif-\nficult to unambiguously select. The ScholarPhi design addresses\nthese challenges. First, it aims to reduce distraction by showing def-\ninitions with high economy: glosses show multiple definitions and\nand in-context usages within a compact tooltip. Second, it provides\nposition-sensitive definitions, revealing definitions that appears\nmost recently prior to the selected usages of terms. Terms and def-\ninitions are automatically identified using a pretrained language\nmodel [ 42 ]. Finally, it provides easier access to definitions of math-\nematical symbols. Readers can access definitions of both a symbol\nand the subsymbols it is made of through a multi-click, ‚Äúdrill-down‚Äù\nselection mechanism. Furthermore, when a reader selects a formula,\nthey can see definitions for all symbols at once, automatically placed\nadjacent to the symbols in the formula‚Äôs margins (see Figure 5).\nIn a usability study, the ",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "ScholarPhi",
    "page": 5,
    "text": "ore, when a reader selects a formula,\nthey can see definitions for all symbols at once, automatically placed\nadjacent to the symbols in the formula‚Äôs margins (see Figure 5).\nIn a usability study, the above interactions reduced the time\nit took readers to find answers to questions involving the under-\nstanding of terminology. All readers reported they would use the\ndefinition tooltips and formula diagrams often or always if available\nin their PDF reader tools.",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "Plain",
    "page": 5,
    "text": "Helping a reader understand individual terms and phrases only\naddresses part of the problem. Papers often contain passages so\ndense and complex that individual definitions are not enough to\nhelp someone read the passages, especially if they are a novice\nor non-expert in a field [ 9 ]. Can we make complex texts more\napproachable by incorporating plain language summaries in the\nmargins of the text? With Paper Plain [ 1 ], when a reader encounters\na section they find difficult to read, they can access a plain language\nsummary of that section by clicking a button adjacent to the section",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "Fusing Papers and Videos with Papeo",
    "page": 6,
    "text": "Sometimes, the best explanation of an idea is non-textual. Videos\ncan enhance understanding [ 65 ] while also requiring less mental\nload [ 66 ], and various tools have been designed to facilitate search-\ning and browsing for explanations in informational videos such\nas lectures [ 47 , 52 , 57 , 76 ] and tutorials [ 46 , 48 , 93 ]. Similarly, for\nresearch papers, an algorithm might be better explained through an\nanimation, a user interface might be better showcased through an\nscreen recording, compared to the proses of a paper [ 37 ]. Instead\nof consuming the two formats independently, could interactive\nreading interfaces offer readers access to these alternative, more\npowerful descriptive forms as they read? For this, Papeo [ 92 ] was\ndeveloped as a tool that supplements papers with more engaging,\nconcise, dynamic presentations of information by linking excerpts\nof talk videos to corresponding paper passages. To grant authors\nmore control over how their work is presented, we developed an AI-\nsupported authoring interface for linking paper passages and videos\nefficiently: candidate passages are linked to excerpts of videos as\nsuggestions using a pretrained language model [ 100 ], an",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "Fusing Papers and Videos with Papeo",
    "page": 6,
    "text": "an AI-\nsupported authoring interface for linking paper passages and videos\nefficiently: candidate passages are linked to excerpts of videos as\nsuggestions using a pretrained language model [ 100 ], and an author\ninteractively confirms or refines them.\nUnlike text-skimming with Scim (¬ß3.1) and Paper Plain (¬ß4.2),\nvideo-skimming in Papeo combines multiple modalities to explain\ncomplex information. For example, instead of reading a long text\ndescription of an interactive system, readers could see the system‚Äôs\nbehavior in a screen recording video with the author‚Äôs commentary,\nand switch to corresponding passages to see implementation details\nor design motivations if desired. Our early-stage evaluations of\nPapeo suggest that readers can use these interactions to fluidly\ntransition between watching video and reading text, using video to\nquickly understand, and then selectively descending into the text\nwhen they desire a detailed understanding of the paper.",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "WORK SECTIONS",
    "page": 6,
    "text": "Scientific breakthroughs often rely upon scholars synthesizing mul-\ntiple published works into broad overviews to identify gaps in the",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "WORK SECTIONS",
    "page": 6,
    "text": "Figure 7: Papeo [92] enables authors to map segments of talk\nvideos to relevant passages in the paper, allowing readers to\nfluidly switch between the two formats. Color-coded bars\nshow the mapping between the two formats, and allow read-\ners to scrub through video segments for quick previews.",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "WORK SECTIONS",
    "page": 6,
    "text": "current literature [ 81 ]. For this, scholars periodically compile sur-\nvey articles to help other scholars gain a comprehensive overview\nof important research topics. For example, some fields have ded-\nicated outlet for such articles (e.g., the Psychological Bulletin [ 5 ]).\nHowever, survey articles require significant time and effort to syn-\nthesize, and can quickly become outdated with the exponential\ngrowth of scientific publication [7].\nInstead, scholars in fast-paced disciplines often rely on the re-\nlated work section when they need to better understand the broader\nbackground when reading a paper. While related work sections also\nsummarize multiple prior works, unlike comprehensive survey arti-\ncles, they typically provide partial views of the larger research topic\nmost relevant to a single paper. There is an opportunity to build bet-\nter tooling for scholars to consume and synthesize multiple related\nwork sections across many papers to gain richer and more compre-\nhensive overviews of fast-paced domains. The Threddy [ 43 ] and\nRelated [ 73 ] projects explored this opportunity using two different\napproaches: clipping and organizing research threads mentioned\nacross papers [ ",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "WORK SECTIONS",
    "page": 6,
    "text": "iews of fast-paced domains. The Threddy [ 43 ] and\nRelated [ 73 ] projects explored this opportunity using two different\napproaches: clipping and organizing research threads mentioned\nacross papers [ 43 ], and directly exploring and reading related work\nsections extracted across many papers [73].",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "with Threddy",
    "page": 6,
    "text": "Clipping and note-taking is one common approach to supporting\nsynthesis across multiple documents. Prior work has pointed to\nthe importance of tightly integrating clipping and synthesis sup-\nport in the reading process, and how incurring significant context-\nswitching costs can be detrimental to sensemaking [ 51 , 79 , 84 ].\nTherefore, recent work has developed tools aimed at reducing the\ncognitive and interaction costs of clipping [ 12 , 60 ] and structur-\ning [ 13 , 53 , 58 , 59 , 88 ] to support everyday online researchers [ 13 ],\nprogrammers [ 58 ], and students [ 88 ]. However, designing clipping\nand synthesis support tools for research papers is relatively under-\nexplored and introduces exciting new research opportunities. For\nexample, additional organizational structures for literature reviews",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "Sections across Papers with Relatedly",
    "page": 7,
    "text": "In contrast to Threddy, which aims to improve readers‚Äô existing\nliterature review process through enhanced in-situ clipping and\nsynthesis [ 43 ], the Relatedly system introduced a novel workflow\nthat allows readers to explore many related work sections across\npapers in an interactive search and reading interface to quickly\ngain a comprehensive overview of rich research topics [ 73 ]. While\nprior work have explored providing overview structure of multiple\ndocuments based on citations [ 16 , 80 ], semantic similarity [ 36 , 85 ],\nor human computation [ 14 , 31 , 62 ], they could still lead to com-\nplex structures that are hard to interpret [ 35 ] or require significant\ncrowdsourcing efforts. Relatedly sidesteps these issues by reusing\nexisting related work paragraphs in published papers which already\ncite sets of related references with descriptions connecting them\n[ 73 ]. As an example, consider a scholar trying to better understand\nthe space of online misinformation . With online misinformation as\nthe query term, Relatedly shows the reader a list of paragraphs\nthat describe and cite multiple relevant prior work. Using a pre-\ntrained language model for summarization [ 56 ], Relatedl",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "Sections across Papers with Relatedly",
    "page": 7,
    "text": "formation as\nthe query term, Relatedly shows the reader a list of paragraphs\nthat describe and cite multiple relevant prior work. Using a pre-\ntrained language model for summarization [ 56 ], Relatedly generates\nshort and descriptive titles for each paragraph, and uses a diversity-\nbased ranking algorithm so that the reader can quickly see and\nexplore paragraphs describing different research threads, such as\nFact Checking Datasets , Social Media and Misinformation , and Fake\nNews Detection Techniques .\nOne challenge here is that paragraphs of the same threads often\ncite overlapping prior work, making them hard to explore and read\nwhile keeping track of which papers were new versus already ex-\nplored. For this, Relatedly provides reading and cross-referencing\nsupport by keeping track of paragraphs and references explored by\nthe readers. This allows Relatedly to help readers prioritize their\nreading for both breadth and depth. Specifically, Relatedly dynam-\nically re-ranks paragraphs and highlights sentences to spotlight\nunexplored and dissimilar references for breadth, but also allow",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "Sections across Papers with Relatedly",
    "page": 7,
    "text": "readers to explore clusters of paragraphs that cited similar refer-\nences for depth. A usability study comparing Relatedly to a strong\ndocument-centric baseline showed that Relatedly led to participants\nwriting summaries that were rated significantly more coherent, in-\nsightful, and detailed after 20 minutes of literature review.",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "ACCESSIBILITY",
    "page": 7,
    "text": "A range of disabilities cause people to read scientific documents\nusing a wide variety of devices and reading tools. For example,\nblind and low vision readers may use assistive reading technology\nsuch as screen readers, screen magnification, or text-to-speech to\nread documents [ 90 ]. Furthermore, people without disabilities face\nsituational impairments, such as the inability to view a screen while\ndriving or may have a preference for consuming content on a small,\nmobile device.\nMany of these reading tools, such as screen readers, do not\nfunction properly on document formats designed for print such as\nPDF unless the document has been manually post-processed to add\ninformation about reading order, content type, etc., which is rarely\nperformed on scientific documents [ 6 , 98 ]. Further, certain content\nelements such as figures require the addition of alternative text in\norder to be read aloud at all (figure captions typically assume the\nreader can see the figure and do not provide the same semantic\ncontent as alt text). High magnification reduces the viewport (the\namount of visible content) and can dramatically increase the amount\nof scrolling and panning required, especially for mu",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "ACCESSIBILITY",
    "page": 7,
    "text": "ame semantic\ncontent as alt text). High magnification reduces the viewport (the\namount of visible content) and can dramatically increase the amount\nof scrolling and panning required, especially for multi-columnar\nformats that are commonly used by scientific documents. Visual\nscanning for information may be impacted or unavailable in these\nsettings, making it more difficult to find and navigate between\ncontent in the document [75].\nOne way to render legacy PDF content more accessibly is to parse\nand convert it into a more flexible format, such as XML or HTML,\nwhich can then be formatted for mobile devices and augmented\nfor reading by screen readers. The SciA11y system 6 demonstrates\nthis approach, automatically converting 12M academic PDFs to\nHTML [ 97 ]; a user study with blind and low vision participants\ndemonstrated strong user appreciation of the output, though some\nerrors remain (e.g., failing in certain cases to distinguish footnotes\nfrom body text, difficulty parsing math equations) [ 98 ]. When avail-\nable, alt text can be automatically categorized into semantic content\ntypes, enabling new reading experiences that allow skipping or\nprioritizing certain types [ 19 ]. Other ap",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "ACCESSIBILITY",
    "page": 7,
    "text": "ns) [ 98 ]. When avail-\nable, alt text can be automatically categorized into semantic content\ntypes, enabling new reading experiences that allow skipping or\nprioritizing certain types [ 19 ]. Other approaches provide comple-\nmentary benefits, such as interfaces tailored for low-vision readers\n(¬ß 3.2), as well as the range of reading support systems outlined\nabove.",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "DISCUSSION AND FUTURE WORK",
    "page": 7,
    "text": "There are additional directions to explore to better support scholarly\nactivities through the Semantic Reader Project.",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "DISCUSSION AND FUTURE WORK",
    "page": 7,
    "text": "Towards a full-featured reading experience. One question is how\nto integrate the different kinds of functionality across these projects\ninto one coherent user interface, especially as we migrate research\nfeatures into the production interface. Another question is how",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "DISCUSSION AND FUTURE WORK",
    "page": 7,
    "text": "6 A demo of a subsequent version is available at https://papertohtml.org/",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "CONCLUSION",
    "page": 8,
    "text": "This paper describes the Semantic Reader Project, which currently\nconsists of ten research prototypes focusing on supporting scien-\ntists around Discovery [ 15 , 82 ], Efficiency [ 28 , 75 ], Comprehen-\nsion [1, 33, 92], Synthesis [43, 73], and Accessibility [91, 97] when\nreading research papers. Validating our approach of augmenting\nexisting PDFs of research papers, we have seen tremendous adop-\ntion of the freely-available Semantic Reader product 1 which has\ngrown to 10k weekly users. 7 While we focused on augmenting PDF\ndocuments to support common scholar reading practices, all of\nour reading interfaces are built with web technologies‚Äîallowing\nthese novel interactions to extend to future publication formats\nwhich can be rendered in web browsers. We plan to continue exper-\nimenting with novel AI-powered intelligent reading interfaces, as\nwell as migrating successful interactive features into the product.\nFinally, we offer a collection of freely-available resources to the\nlarger research community, including datasets of open-access re-\nsearch papers [ 61 ], APIs for accessing the academic citation graph\n[ 50 ], machine learning models for processing and understanding\nresearch pape",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "CONCLUSION",
    "page": 8,
    "text": "rch community, including datasets of open-access re-\nsearch papers [ 61 ], APIs for accessing the academic citation graph\n[ 50 ], machine learning models for processing and understanding\nresearch papers [ 11 , 20 , 42 , 86 ], 4 and open-source software for ren-\ndering and augmenting PDF documents for developing reading\ninterfaces. 3 We hope by providing these resources we can enable\nand encourage the broader research community to work on exciting\nnovel intelligent reading interfaces for research papers with us.",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "CONCLUSION",
    "page": 8,
    "text": "7 As of late February, 2023",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "REFERENCES",
    "page": 9,
    "text": "[1] Tal August, Lucy Lu Wang, Jonathan Bragg, Marti A. Hearst, Andrew Head, and\nKyle Lo. 2023. Paper Plain: Making Medical Research Papers Approachable to\nHealthcare Consumers with Natural Language Processing. ACM Transactions\non Computer-Human Interaction (2023). To appear.\n[2] Charles Bazerman. 1985. Physicists reading physics: Schema-Laden Purposes\nand Purpose-Laden Schema. Written Communication 2, 1 (Jan. 1985), 3‚Äì23.\n[3] Joeran Beel and Bela Gipp. 2009. Google Scholar‚Äôs ranking algorithm: The impact\nof citation counts (An empirical study). 2009 Third International Conference on\nResearch Challenges in Information Science (2009), 439‚Äì446.\n[4] Iz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciBERT: A Pretrained Language\nModel for Scientific Text. In Conference on Empirical Methods in Natural Lan-\nguage Processing .\n[5] Daryl J Bem. 1995. Writing a review article for Psychological Bulletin. Psycho-\nlogical Bulletin 118, 2 (1995), 172.\n[6] Jeffrey P. Bigham, Erin L. Brady, Cole Gleason, Anhong Guo, and David A.\nShamma. 2016. An Uninteresting Tour Through Why Our Research Papers\nAren‚Äôt Accessible. In Proceedings of the 2016 CHI Conference Extended Abstracts\non Human Factors in Computin",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "REFERENCES",
    "page": 9,
    "text": "nhong Guo, and David A.\nShamma. 2016. An Uninteresting Tour Through Why Our Research Papers\nAren‚Äôt Accessible. In Proceedings of the 2016 CHI Conference Extended Abstracts\non Human Factors in Computing Systems (San Jose, California, USA) (CHI EA ‚Äô16) .\nAssociation for Computing Machinery, New York, NY, USA, 621‚Äì631. https:\n//doi.org/10.1145/2851581.2892588\n[7] Lutz Bornmann, Ruediger Mutz, and Robin Haunschild. 2020. Growth rates of\nmodern science: a latent piecewise growth curve approach to model publication\nnumbers from established and new literature databases. Humanities and Social\nSciences Communications 8 (2020), 1‚Äì15.\n[8] Jeffrey Brainard. 2020. Scientists are drowning in COVID-19 papers. Can new\ntools keep them afloat. Science 13, 10 (2020), 1126.\n[9] Mary Anne Britt, Tobias Richter, and Jean-Fran√ßois Rouet. 2014. Scientific\nLiteracy: The Role of Goal-Directed Reading and Evaluation in Understanding\nScientific Information. Educational Psychologist 49 (2014), 104 ‚Äì 122.\n[10] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Ka-\nplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,\nAmanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen K",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "REFERENCES",
    "page": 9,
    "text": "Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Ka-\nplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry,\nAmanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger,\nTom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu,\nClemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott\nGray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage Models are\nFew-Shot Learners. In Advances in Neural Information Processing Systems ,\nH. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (Eds.), Vol. 33.\nCurran Associates, Inc., 1877‚Äì1901. https://proceedings.neurips.cc/paper/2020/\nfile/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf\n[11] Isabel Cachola, Kyle Lo, Arman Cohan, and Daniel S. Weld. 2020. TLDR: Extreme\nSummarization of Scientific Documents. In Findings of EMNLP .\n[12] Joseph Chee Chang, Nathan Hahn, and Aniket Kittur. 2016. Supporting Mobile\nSensemaking Through Intentionally Uncertain Highlighting. In Proceedings of\nthe 29th Annual Symposium on User Interface Software and Technology (Tokyo,\nJapan) (UIST ‚Äô16) . Association for Computing",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "REFERENCES",
    "page": 9,
    "text": "le\nSensemaking Through Intentionally Uncertain Highlighting. In Proceedings of\nthe 29th Annual Symposium on User Interface Software and Technology (Tokyo,\nJapan) (UIST ‚Äô16) . Association for Computing Machinery, New York, NY, USA,\n61‚Äì68. https://doi.org/10.1145/2984511.2984538\n[13] Joseph Chee Chang, Nathan Hahn, and Aniket Kittur. 2020. Mesh: Scaffolding\nComparison Tables for Online Decision Making. In Proceedings of the 33rd\nAnnual ACM Symposium on User Interface Software and Technology (Virtual\nEvent, USA) (UIST ‚Äô20) . Association for Computing Machinery, New York, NY,\nUSA, 391‚Äì405. https://doi.org/10.1145/3379337.3415865\n[14] Joseph Chee Chang, Aniket Kittur, and Nathan Hahn. 2016. Alloy: Clustering\nwith crowds and computation. In Proceedings of the 2016 CHI Conference on\nHuman Factors in Computing Systems . 3180‚Äì3191.\n[15] Joseph Chee Chang, Amy X Zhang, Jonathan Bragg, Andrew Head, Kyle Lo,\nDoug Downey, and Daniel S Weld. 2023. CiteSee: Augmenting Citations in\nScientific Papers with Persistent and Personalized Historical Context. ArXiv\nabs/2022.99999 (2023).\n[16] Duen Horng Chau, Aniket Kittur, Jason I Hong, and Christos Faloutsos. 2011.\nApolo: making sense of large network d",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "REFERENCES",
    "page": 9,
    "text": "ith Persistent and Personalized Historical Context. ArXiv\nabs/2022.99999 (2023).\n[16] Duen Horng Chau, Aniket Kittur, Jason I Hong, and Christos Faloutsos. 2011.\nApolo: making sense of large network data by combining rich user interaction\nand machine learning. In Proceedings of the SIGCHI conference on human factors\nin computing systems . 167‚Äì176.\n[17] Vinay K. Chaudhri, Britte Haugan Cheng, Adam Overholtzer, Jeremy Roschelle,\nAaron Spaulding, Peter E. Clark, Mark T. Greaves, and David Gunning. 2013.\nInquire Biology: A Textbook that Answers Questions. AI Mag. 34 (2013), 55‚Äì72.\n[18] Ed H. Chi, Lichan Hong, Michelle Gumbrecht, and Stuart K. Card. 2005. Scen-\ntHighlights: highlighting conceptually-related sentences during reading. In\nProceedings of the 10th International Conference on Intelligent User Interfaces .",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "REFERENCES",
    "page": 9,
    "text": "Association for Computing Machinery, San Diego, CA, USA, 272.\n[19] Sanjana Shivani Chintalapati, Jonathan Bragg, and Lucy Lu Wang. 2022. A\nDataset of Alt Texts from HCI Publications: Analyses and Uses Towards Pro-\nducing More Descriptive Alt Texts of Data Visualizations in Scientific Pa-\npers. In Proceedings of the 24th International ACM SIGACCESS Conference on\nComputers and Accessibility (Athens, Greece) (ASSETS ‚Äô22) . Association for\nComputing Machinery, New York, NY, USA, Article 30, 12 pages.\nhttps:\n//doi.org/10.1145/3517428.3544796\n[20] Arman Cohan, Sergey Feldman, Iz Beltagy, Doug Downey, and Daniel S Weld.\n2020. Specter: Document-level representation learning using citation-informed\ntransformers. arXiv preprint arXiv:2004.07180 (2020).\n[21] Matthew Conlen and Jeffrey Heer. 2022. Fidyll: A Compiler for Cross-Format\nData Stories & Explorable Explanations. ArXiv abs/2205.09858 (2022).\n[22] Matthew Conlen, Megan Vo, Alan Tan, and Jeffrey Heer. 2021. Idyll studio: A\nstructured editor for authoring interactive & data-driven articles. In The 34th\nAnnual ACM Symposium on User Interface Software and Technology . 1‚Äì12.\n[23] Pradeep Dasigi, Kyle Lo, Iz Beltagy, Arman Cohan, Noah A. Smi",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "REFERENCES",
    "page": 9,
    "text": " for authoring interactive & data-driven articles. In The 34th\nAnnual ACM Symposium on User Interface Software and Technology . 1‚Äì12.\n[23] Pradeep Dasigi, Kyle Lo, Iz Beltagy, Arman Cohan, Noah A. Smith, and Matt\nGardner. 2021. A Dataset of Information-Seeking Questions and Answers An-\nchored in Research Papers. In Proceedings of the 2021 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics: Human Lan-\nguage Technologies . Association for Computational Linguistics, Online, 4599‚Äì\n4610. https://doi.org/10.18653/v1/2021.naacl-main.365\n[24] Andrew S. Denney and Richard Allan Tewksbury. 2013. How to Write a Litera-\nture Review. Journal of Criminal Justice Education 24 (2013), 218 ‚Äì 234.\n[25] Graham Dove, Kim Halskov, Jodi Forlizzi, and John Zimmerman. 2017. UX\ndesign innovation: Challenges for working with machine learning as a design\nmaterial. In Proceedings of the 2017 chi conference on human factors in computing\nsystems . 278‚Äì288.\n[26] Kristina Dzara and Ariel S Frey-Vogel. 2019. Medical Education Journal Club for\nthe Millennial Resident: An Interactive, No-Prep Approach. Academic pediatrics\n(2019).\n[27] Editorial Team. 2021. Distill Hiatus. Disti",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "REFERENCES",
    "page": 9,
    "text": "and Ariel S Frey-Vogel. 2019. Medical Education Journal Club for\nthe Millennial Resident: An Interactive, No-Prep Approach. Academic pediatrics\n(2019).\n[27] Editorial Team. 2021. Distill Hiatus. Distill 6, 7 (July 2021). https://doi.org/10.\n23915/distill.00031\n[28] Raymond Fok, Hita Kambhamettu, Luca Soldaini, Jonathan Bragg, Kyle Lo,\nAndrew Head, Marti A. Hearst, and Daniel S. Weld. 2023. Scim: Intelligent\nSkimming Support for Scientific Papers. In 28th Annual Conference on Intelligent\nUser Interfaces (IUI ‚Äô23) .\n[29] Paul Ginsparg. 2011. ArXiv at 20. Nature 476, 7359 (2011), 145‚Äì147.\n[30] Marco Gori and Augusto Pucci. 2006. Research Paper Recommender Systems: A\nRandom-Walk Based Approach. 2006 IEEE/WIC/ACM International Conference on\nWeb Intelligence (WI 2006 Main Conference Proceedings)(WI‚Äô06) (2006), 778‚Äì781.\n[31] Nathan Hahn, Joseph Chang, Ji Eun Kim, and Aniket Kittur. 2016. The Knowl-\nedge Accelerator: Big picture thinking in small pieces. In Proceedings of the 2016\nCHI Conference on Human Factors in Computing Systems . 2258‚Äì2270.\n[32] Jiangen He, Q. Ping, Wen Lou, and Chaomei Chen. 2019. PaperPoles: Facilitating\nadaptive visual exploration of scientific publications by cita",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "REFERENCES",
    "page": 9,
    "text": "ce on Human Factors in Computing Systems . 2258‚Äì2270.\n[32] Jiangen He, Q. Ping, Wen Lou, and Chaomei Chen. 2019. PaperPoles: Facilitating\nadaptive visual exploration of scientific publications by citation links. Journal\nof the Association for Information Science and Technology 70 (2019).\n[33] Andrew Head, Kyle Lo, Dongyeop Kang, Raymond Fok, Sam Skjonsberg,\nDaniel S. Weld, and Marti A. Hearst. 2021. Augmenting Scientific Papers with\nJust-in-Time, Position-Sensitive Definitions of Terms and Symbols. Proceedings\nof the 2021 CHI Conference on Human Factors in Computing Systems (2021).\n[34] Andrew Head, Amber Xie, and Marti A Hearst. 2022. Math Augmentation:\nHow Authors Enhance the Readability of Formulas using Novel Visual Design\nPractices. In CHI Conference on Human Factors in Computing Systems . 1‚Äì18.\n[35] Marti A Hearst. 1999. The use of categories and clusters for organizing retrieval\nresults. Natural language information retrieval (1999), 333‚Äì374.\n[36] Marti A Hearst. 2006. Clustering versus faceted categories for information\nexploration. Commun. ACM 49, 4 (2006), 59‚Äì61.\n[37] Tim Niclas H√∂ffler and Detlev Leutner. 2007. Instructional animation versus\nstatic pictures: A meta-analy",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "REFERENCES",
    "page": 9,
    "text": "g versus faceted categories for information\nexploration. Commun. ACM 49, 4 (2006), 59‚Äì61.\n[37] Tim Niclas H√∂ffler and Detlev Leutner. 2007. Instructional animation versus\nstatic pictures: A meta-analysis. Learning and Instruction 17 (2007), 722‚Äì738.\n[38] Fred Hohman, Matthew Conlen, Jeffrey Heer, and Duen Horng Chau. 2020.\nCommunicating with Interactive Articles. Distill .\nhttps://doi.org/10.23915/\ndistill.00028\n[39] Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, and Furu Wei. 2022. Lay-\noutLMv3: Pre-training for Document AI with Unified Text and Image Masking.\nProceedings of the 30th ACM International Conference on Multimedia (2022).\n[40] Zan Huang, Wingyan Chung, Thian-Huat Ong, and Hsinchun Chen. 2002. A\ngraph-based recommender system for digital library. In JCDL ‚Äô02 .\n[41] Abhinav Jain, Nitin Gupta, Shashank Mujumdar, Sameep Mehta, and Rishi\nMadhok. 2018. Content Driven Enrichment of Formal Text using Concept\nDefinitions and Applications. Proceedings of the 29th on Hypertext and Social\nMedia (2018).\n[42] Dongyeop Kang, Andrew Head, Risham Sidhu, Kyle Lo, Daniel Weld, and Marti A.\nHearst. 2020. Document-Level Definition Detection in Scholarly Documents:\nExisting Models, Error Ana",
    "images": null
  },
  {
    "doc_id": "2303.14334v2",
    "title": "REFERENCES",
    "page": 9,
    "text": "ial\nMedia (2018).\n[42] Dongyeop Kang, Andrew Head, Risham Sidhu, Kyle Lo, Daniel Weld, and Marti A.\nHearst. 2020. Document-Level Definition Detection in Scholarly Documents:\nExisting Models, Error Analyses, and Future Directions. In Proceedings of the\nFirst Workshop on Scholarly Document Processing . Association for Computational\nLinguistics, Online, 196‚Äì206. https://doi.org/10.18653/v1/2020.sdp-1.22",
    "images": null
  }
]