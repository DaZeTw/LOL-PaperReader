<table><caption><div class="caption">Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the English-to-German and English-to-French newstest2014 tests at a fraction of the training cost.</div></caption><tbody><tr><th>Model</th><th colspan="2">BLEU</th><th colspan="2">Training Cost (FLOPs)</th></tr><tr><td></td><th>EN-DE</th><th>EN-FR</th><th>EN-DE</th><th>EN-FR</th></tr><tr><th>ByteNet [18]</th><td>23.75</td><td></td><td></td><td></td></tr><tr><th>Deep-Att + PosUnk [39]</th><td></td><td>39.2</td><td></td><td>1 . 0 · 10 20</td></tr><tr><th>GNMT + RL [38]</th><td>24.6</td><td>39.92</td><td>2 . 3 · 10 19</td><td>1 . 4 · 10 20</td></tr><tr><th>ConvS2S [9]</th><td>25.16</td><td>40.46</td><td>9 . 6 · 10 18</td><td>1 . 5 · 10 20</td></tr><tr><th>MoE [32]</th><td>26.03</td><td>40.56</td><td>2 . 0 · 10 19</td><td>1 . 2 · 10 20</td></tr><tr><th>Deep-Att + PosUnk Ensemble [39]</th><td></td><td>40.4</td><td></td><td>8 . 0 · 10 20</td></tr><tr><th>GNMT + RL Ensemble [38]</th><td>26.30</td><td>41.16</td><td>1 . 8 · 10 20</td><td>1 . 1 · 10 21</td></tr><tr><th>ConvS2S Ensemble [9]</th><td>26.36</td><td>41.29</td><td>7 . 7 · 10 19</td><td>1 . 2 · 10 21</td></tr><tr><th>Transformer (base model)</th><td>27.3</td><td>38.1</td><td colspan="2">3 . 3 · 10 18</td></tr><tr><th>Transformer (big)</th><td>28.4</td><td>41.8</td><td colspan="2">2 . 3 · 10 19</td></tr></tbody></table>