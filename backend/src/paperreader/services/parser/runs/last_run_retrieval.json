{
  "question": "what method this paper use",
  "hits": [
    {
      "index": 6,
      "score": 0.3324468035009158,
      "text": "However, once they find one research paper, it’s\nespecially common for scholars to use its references and citations\nto further expand their knowledge of a research area. This behavior,\nsometimes referred to as forward/backward chaining or footnote\nchasing , is ubiquitous and has been observed across many schol-\narly disciplines [ 74 ]. Supporting this, one popular feature in the\nSemantic Reader 1 is in-situ Paper Cards that pop up when readers\nclick on an inline citation, dramatically reducing the interaction\ncost caused by jumping back-and-forth between inline citations\nand their corresponding references at the end of a research paper\n(Figure 1). Despite this affordance, during literature reviews, read-\ners may still be overwhelmed trying to make sense of the tens to\nhundreds of inline citations in each paper [ 15 , 24 , 77 ]. Conversely,\nwhen reading a given paper, a reader cannot see relevant follow-on\nresearch papers that cited the current paper. Here we discuss how\ninteractive reading interfaces can help scholars more effectively\nexplore citations to important relevant work in both directions with\ntwo systems called CiteSee [15] and CiteRead [82].",
      "metadata": {
        "doc_id": "2303.14334v2-embedded",
        "title": "UNLOCKING CITATIONS FOR DISCOVERY",
        "page": 3,
        "images": []
      }
    },
    {
      "index": 14,
      "score": 0.30935683628264854,
      "text": "abstracts offer one such separation, in essence an author-crafted\ndetermination of relevant content. However, static paper abstracts\ncan leave readers to desire additional details that then require them\nto skim the paper itself.\nScim [ 28 ] addresses this problem via an augmented reading\ninterface designed to guide readers’ attention using automatically-\ncreated in-situ faceted highlights (Figure 4). Though prior work\nhas explored highlighting as a visual cue for guiding reader atten-\ntion [ 18 , 102 , 105 ], the efficacy for reading of scholarly text is less\nwell-understood. Scim investigated the following design goals for\nintelligent highlights in scholarly reading: highlights should be\n(1) evenly-distributed throughout a paper, (2) have just the right\ndensity (too few highlights will present the guise of an inept tool,\nand too many will slow a reader down), and (3) highlight several\nkey categories of information in the paper. Because readers often\nskim for common types of information, Scim uses a pretrained lan-\nguage model [ 99 ] to classify salient sentences within papers into\none of four information facets: research objectives, novel aspects\nof the research, methodology, and results, coupled with heuristics\nthat ensure an even distribution of highlights. Usability studies\nof Scim have shown these highlights can reduce the time it takes\nreaders to find specific information within a paper. Readers found\nScim particularly useful when skimming text-dense papers, or for\npapers that fell outside their area of expertise. Moreover, readers\nlearned to use both Scim’s inline highlights and a sidebar summary\nof highlights to augment their existing reading strategies.",
      "metadata": {
        "doc_id": "2303.14334v2-embedded",
        "title": "Guided Reading with Scim",
        "page": 4,
        "images": []
      }
    },
    {
      "index": 12,
      "score": 0.30557791728112105,
      "text": "Non-linear navigation can be especially burdensome when\nthe reader is interested in a particular type of information (e.g.,\nskimming a paper for the main results), but doesn’t know precisely\nwhere to find it within the paper. In this section we discuss two\nsystems, Scim [ 28 ] and Ocean [ 75 ], which demonstrate different\napproaches to helping readers navigate efficiently through a paper\ntoward high-value, relevant information.",
      "metadata": {
        "doc_id": "2303.14334v2-embedded",
        "title": "NAVIGATION AND EFFICIENT READING",
        "page": 4,
        "images": []
      }
    },
    {
      "index": 5,
      "score": 0.30281946055170395,
      "text": "Scholars use many methods to discover relevant research papers\nto read, including search engines, word of mouth, and browsing\nfamiliar venues.",
      "metadata": {
        "doc_id": "2303.14334v2-embedded",
        "title": "UNLOCKING CITATIONS FOR DISCOVERY",
        "page": 3,
        "images": []
      }
    },
    {
      "index": 35,
      "score": 0.2552048970518061,
      "text": "This paper describes the Semantic Reader Project, which currently\nconsists of ten research prototypes focusing on supporting scien-\ntists around Discovery [ 15 , 82 ], Efficiency [ 28 , 75 ], Comprehen-\nsion [1, 33, 92], Synthesis [43, 73], and Accessibility [91, 97] when\nreading research papers. Validating our approach of augmenting\nexisting PDFs of research papers, we have seen tremendous adop-\ntion of the freely-available Semantic Reader product 1 which has\ngrown to 10k weekly users. 7 While we focused on augmenting PDF\ndocuments to support common scholar reading practices, all of\nour reading interfaces are built with web technologies—allowing\nthese novel interactions to extend to future publication formats\nwhich can be rendered in web browsers. We plan to continue exper-\nimenting with novel AI-powered intelligent reading interfaces, as\nwell as migrating successful interactive features into the product.\nFinally, we offer a collection of freely-available resources to the\nlarger research community, including datasets of open-access re-\nsearch papers [ 61 ], APIs for accessing the academic citation graph\n[ 50 ], machine learning models for processing and understanding\nresearch papers [ 11 , 20 , 42 , 86 ], 4 and open-source software for ren-\ndering and augmenting PDF documents for developing reading\ninterfaces. 3 We hope by providing these resources we can enable\nand encourage the broader research community to work on exciting\nnovel intelligent reading interfaces for research papers with us.",
      "metadata": {
        "doc_id": "2303.14334v2-embedded",
        "title": "CONCLUSION",
        "page": 8,
        "images": []
      }
    }
  ]
}