{
  "question": "vậy finding bài này là gì",
  "hits": [
    {
      "index": 0,
      "score": 0.7467831,
      "text": "2025. Bingo: Radix-based Bias Factorization for Random Walk on Dynamic Graphs. In Proceedings of the Twentieth European Conference on Computer Systems (Rotterdam, Netherlands) (EuroSys ’25) . Association for Computing Machinery, 16 pages. [57] Shenao Wang, Yanjie Zhao, Xinyi Hou, and Haoyu Wang. 2024. Large language model supply chain: A research agenda. ACM Transactions on Software Engineer- ing and Methodology (2024). [58] Mengwei Xu, Wangsong Yin, Dongqi Cai, Rongjie Yi, Daliang Xu, Qipeng Wang, Bingyang Wu, Yihao Zhao, Chen Yang, Shihe Wang, et al . 2024. A survey of resource-efficient llm and multimodal foundation models. arXiv preprint arXiv:2401.08092 (2024). [59] Zhuoyan Xu, Zhenmei Shi, Junyi Wei, Fangzhou Mu, Yin Li, and Yingyu Liang. 2024. Towards Few-Shot Adaptation of Foundation Models via Multitask Fine- tuning. arXiv preprint arXiv:2402.15017 (2024).",
      "metadata": {
        "chunk_id": "7652f06d3834a156821eb0a3650665da6a2e30ad",
        "doc_id": "2507.14240v3",
        "page": 9,
        "images": [],
        "tables": []
      }
    },
    {
      "index": 1,
      "score": 0.73435104,
      "text": "IEEE, 88–93. [14] Hugging Face. [n. d.]. Hugging Face – The AI community building the future. https://huggingface.co/ [15] Wang Feng, Shiyang Chen, Hang Liu, and Yuede Ji. 2023. Peek: A Prune-Centric Approach for K Shortest Path Computation. In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis . 1–14. [16] Qiang Fu, Yuede Ji, and H Howie Huang.",
      "metadata": {
        "chunk_id": "e9d3c9680bf4d49697869b59d21e830be405b53b",
        "doc_id": "2507.14240v3",
        "page": 8,
        "images": [],
        "tables": []
      }
    },
    {
      "index": 2,
      "score": 0.7341149,
      "text": "2025. Evolu- tionary optimization of model merging recipes. Nature Machine Intelligence 7, 2 (2025), 195–204. [3] Dean Allemang and Juan Sequeda. 2024. Increasing the LLM Accuracy for Question Answering: Ontologies to the Rescue! arXiv preprint arXiv:2405.11706 (2024). [4] Anonymous. 2022. Review of Supply Chain Management in Manufacturing Organizations. ResearchGate (2022). https://www.researchgate.net/publication/ 377659033_Review_of_supply_chain_management_in_manufacturing_ organizations [5] Mourad Bahani, Aziza El Ouaazizi, and Khalil Maalmi. 2023. The effectiveness of T5, GPT-2, and BERT on text-to-image generation task. Pattern Recognition Letters 173 (2023), 57–63. [6] Casper Solheim Bojer and Jens Peder Meldgaard. 2021. Kaggle forecasting compe- titions: An overlooked learning opportunity. International Journal of Forecasting 37, 2 (2021), 587–603. [7] Euan Bonner, Ryan Lege, and Erin Frazier. 2023. Large Language Model-Based Artificial Intelligence in the Language Classroom: Practical Ideas for Teaching. Teaching English with Technology 23, 1 (2023), 23–41. [8] Dalton A Brucker-Hahn, Wang Feng, Shanchao Li, Matthew Petillo, Alexan- dru G Bardas, Drew Davidson, and Yuede Ji.",
      "metadata": {
        "chunk_id": "8bed460c76ca71ac6128ac4fbbb8a19803f8ff5b",
        "doc_id": "2507.14240v3",
        "page": 8,
        "images": [],
        "tables": []
      }
    },
    {
      "index": 3,
      "score": 0.73393446,
      "text": "Acknowledgment This work was supported in part by National Science Foundation grants 2331301, 2508118, 2516003, 2419843. The views, opinions, and/or findings expressed in this material are those of the authors and should not be interpreted as representing the official views of the National Science Foundation, or the U.S. Government.",
      "metadata": {
        "chunk_id": "566ba6d729825c009cf20d832793cc9fa1aa1606",
        "doc_id": "2507.14240v3",
        "page": 7,
        "images": [],
        "tables": []
      }
    },
    {
      "index": 4,
      "score": 0.73021346,
      "text": "1.2 Contribution Our main contributions are threefold. First, we design a methodol- ogy to systematically collect the supply chain information of LLMs. In this paper, we mainly study the most popular AI platform, i.e., Hugging Face, but the same strategy applies to other platforms. In particular, we use the APIs from the AI platform to collect the metadata about the hosted models and datasets.",
      "metadata": {
        "chunk_id": "30255534c81b5efd6c421216dc5b7ba8a3726233",
        "doc_id": "2507.14240v3",
        "page": 2,
        "images": [],
        "tables": []
      }
    }
  ]
}