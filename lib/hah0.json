[
  {
      "str": "1",
      "dir": "ltr",
      "width": 5.9776,
      "height": 11.9552,
      "transform": [
          11.9552,
          0,
          0,
          11.9552,
          108,
          710.037
      ],
      "fontName": "g_d0_f2",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 11.955200000000005,
      "height": 0,
      "transform": [
          11.9552,
          0,
          0,
          11.9552,
          113.9776,
          710.037
      ],
      "fontName": "g_d0_f2",
      "hasEOL": false
  },
  {
      "str": "Introduction",
      "dir": "ltr",
      "width": 64.8808704,
      "height": 11.9552,
      "transform": [
          11.9552,
          0,
          0,
          11.9552,
          125.9328,
          710.037
      ],
      "fontName": "g_d0_f2",
      "hasEOL": false
  },
  {
      "str": "",
      "dir": "ltr",
      "width": 0,
      "height": 0,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          108,
          685.354
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "Recurrent neural networks, long short-term memory [",
      "dir": "ltr",
      "width": 218.95742504400016,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          108,
          685.354
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "13",
      "dir": "ltr",
      "width": 9.9626,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          326.954,
          685.354
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "] and gated recurrent [",
      "dir": "ltr",
      "width": 90.80630947200011,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          336.916,
          685.354
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "7",
      "dir": "ltr",
      "width": 4.9813,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          427.722,
          685.354
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "] neural networks",
      "dir": "ltr",
      "width": 71.29555363200005,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          432.703,
          685.354
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "in particular, have been firmly established as state of the art approaches in sequence modeling and",
      "dir": "ltr",
      "width": 395.9976887927999,
      "height": 9.9626,
      "transform": [
          10.131964199999999,
          0,
          0,
          9.9626,
          108,
          674.445
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "transduction problems such as language modeling and machine translation [",
      "dir": "ltr",
      "width": 312.29403566400003,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          108,
          663.536
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.002964336000502499,
      "height": 0,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          420.2940356639995,
          663.536
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "35",
      "dir": "ltr",
      "width": 9.9626,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          420.297,
          663.536
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.0003921568627581163,
      "height": 0,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          430.2596,
          663.536
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": ",",
      "dir": "ltr",
      "width": 2.540463,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          430.26,
          663.536
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 2.9635370000000307,
      "height": 0,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          432.800463,
          663.536
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "2",
      "dir": "ltr",
      "width": 4.9813,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          435.764,
          663.536
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.0006862745097988391,
      "height": 0,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          440.7453,
          663.536
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": ",",
      "dir": "ltr",
      "width": 2.540463,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          440.746,
          663.536
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 2.964537000000007,
      "height": 0,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          443.28646299999997,
          663.536
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "5",
      "dir": "ltr",
      "width": 4.9813,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          446.251,
          663.536
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "]. Numerous",
      "dir": "ltr",
      "width": 52.77049743599997,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          451.232,
          663.536
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "efforts have since continued to push the boundaries of recurrent language models and encoder-decoder",
      "dir": "ltr",
      "width": 396.1673717959998,
      "height": 9.9626,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          108,
          652.627
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "architectures [38, 24, 15].",
      "dir": "ltr",
      "width": 102.365715,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          108,
          641.718
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "Recurrent models typically factor computation along the symbol positions of the input and output",
      "dir": "ltr",
      "width": 395.9972105879996,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          108,
          625.329
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden",
      "dir": "ltr",
      "width": 395.997011336,
      "height": 9.9626,
      "transform": [
          10.0024504,
          0,
          0,
          9.9626,
          108,
          614.42
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "states",
      "dir": "ltr",
      "width": 21.915528228,
      "height": 9.9626,
      "transform": [
          9.862974,
          0,
          0,
          9.9626,
          108,
          603.511
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 2.5156280525252877,
      "height": 0,
      "transform": [
          9.862974,
          0,
          0,
          9.9626,
          129.91552822799997,
          603.511
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "h",
      "dir": "ltr",
      "width": 5.74045012,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          132.406,
          603.511
      ],
      "fontName": "g_d0_f8",
      "hasEOL": false
  },
  {
      "str": "t",
      "dir": "ltr",
      "width": 3.00989208,
      "height": 6.9738,
      "transform": [
          6.9738,
          0,
          0,
          6.9738,
          138.14600000000002,
          602.0169999999999
      ],
      "fontName": "g_d0_f9",
      "hasEOL": false
  },
  {
      "str": ", as a function of the previous hidden state",
      "dir": "ltr",
      "width": 166.77302736600004,
      "height": 9.9626,
      "transform": [
          9.862974,
          0,
          0,
          9.9626,
          141.654,
          603.511
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 2.5191642767676647,
      "height": 0,
      "transform": [
          9.862974,
          0,
          0,
          9.9626,
          308.427027366,
          603.511
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "h",
      "dir": "ltr",
      "width": 5.74045012,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          310.921,
          603.511
      ],
      "fontName": "g_d0_f8",
      "hasEOL": false
  },
  {
      "str": "t",
      "dir": "ltr",
      "width": 3.00989208,
      "height": 6.9738,
      "transform": [
          6.9738,
          0,
          0,
          6.9738,
          316.661,
          602.0169999999999
      ],
      "fontName": "g_d0_f9",
      "hasEOL": false
  },
  {
      "str": "âˆ’",
      "dir": "ltr",
      "width": 6.2269060199999995,
      "height": 6.9738,
      "transform": [
          6.9738,
          0,
          0,
          6.9738,
          319.67,
          602.0169999999999
      ],
      "fontName": "g_d0_f3",
      "hasEOL": false
  },
  {
      "str": "1",
      "dir": "ltr",
      "width": 3.9715790999999996,
      "height": 6.9738,
      "transform": [
          6.9738,
          0,
          0,
          6.9738,
          325.897,
          602.0169999999999
      ],
      "fontName": "g_d0_f10",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 2.988420900000051,
      "height": 0,
      "transform": [
          6.9738,
          0,
          0,
          6.9738,
          329.8685791,
          602.0169999999999
      ],
      "fontName": "g_d0_f10",
      "hasEOL": false
  },
  {
      "str": "and the input for position",
      "dir": "ltr",
      "width": 99.82315985400001,
      "height": 9.9626,
      "transform": [
          9.862974,
          0,
          0,
          9.9626,
          332.857,
          603.511
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 2.5190304505049608,
      "height": 0,
      "transform": [
          9.862974,
          0,
          0,
          9.9626,
          432.68015985400007,
          603.511
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "t",
      "dir": "ltr",
      "width": 3.5974948600000003,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          435.174,
          603.511
      ],
      "fontName": "g_d0_f8",
      "hasEOL": false
  },
  {
      "str": ". This inherently",
      "dir": "ltr",
      "width": 65.57891412599996,
      "height": 9.9626,
      "transform": [
          9.862974,
          0,
          0,
          9.9626,
          438.772,
          603.511
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "sequential nature precludes parallelization within training examples, which becomes critical at longer",
      "dir": "ltr",
      "width": 396.16737179599977,
      "height": 9.9626,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          108,
          592.602
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved",
      "dir": "ltr",
      "width": 395.9973699895999,
      "height": 9.9626,
      "transform": [
          9.9327122,
          0,
          0,
          9.9626,
          108,
          581.693
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "significant improvements in computational efficiency through factorization tricks [",
      "dir": "ltr",
      "width": 320.27686779199973,
      "height": 9.9626,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          108,
          570.784
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.0011322080005129465,
      "height": 0,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          428.2768677919995,
          570.784
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "21",
      "dir": "ltr",
      "width": 9.9626,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          428.278,
          570.784
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.00040816326531967206,
      "height": 0,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          438.2406,
          570.784
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "] and conditional",
      "dir": "ltr",
      "width": 65.75614877999996,
      "height": 9.9626,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          438.241,
          570.784
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "computation [",
      "dir": "ltr",
      "width": 56.571667690400005,
      "height": 9.9626,
      "transform": [
          10.1419268,
          0,
          0,
          9.9626,
          108,
          559.875
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.004332309599988093,
      "height": 0,
      "transform": [
          10.1419268,
          0,
          0,
          9.9626,
          164.5716676904,
          559.875
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "32",
      "dir": "ltr",
      "width": 9.9626,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          164.576,
          559.875
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.0003929273084330618,
      "height": 0,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          174.5386,
          559.875
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "], while also improving model performance in case of the latter. The fundamental",
      "dir": "ltr",
      "width": 329.4604920980001,
      "height": 9.9626,
      "transform": [
          10.1419268,
          0,
          0,
          9.9626,
          174.539,
          559.875
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "constraint of sequential computation, however, remains.",
      "dir": "ltr",
      "width": 222.52463360000016,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          108,
          548.966
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "Attention mechanisms have become an integral part of compelling sequence modeling and transduc-",
      "dir": "ltr",
      "width": 398.0143182847999,
      "height": 9.9626,
      "transform": [
          9.9028244,
          0,
          0,
          9.9626,
          107.641,
          532.577
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "tion models in various tasks, allowing modeling of dependencies without regard to their distance in",
      "dir": "ltr",
      "width": 395.99701133599956,
      "height": 9.9626,
      "transform": [
          10.0024504,
          0,
          0,
          9.9626,
          108,
          521.668
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "the input or output sequences [",
      "dir": "ltr",
      "width": 119.84509670000008,
      "height": 9.9626,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          108,
          510.759
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.0019032999998955802,
      "height": 0,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          227.8450967000001,
          510.759
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "2",
      "dir": "ltr",
      "width": 4.9813,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          227.847,
          510.759
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": ",",
      "dir": "ltr",
      "width": 2.440837,
      "height": 9.9626,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          232.828,
          510.759
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 2.3851630000000057,
      "height": 0,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          235.268837,
          510.759
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "19",
      "dir": "ltr",
      "width": 9.9626,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          237.654,
          510.759
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.0004081632652906703,
      "height": 0,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          247.6166,
          510.759
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "]. In all but a few cases [",
      "dir": "ltr",
      "width": 95.79797057600004,
      "height": 9.9626,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          247.617,
          510.759
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.0020294240001703656,
      "height": 0,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          343.4149705759998,
          510.759
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "27",
      "dir": "ltr",
      "width": 9.9626,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          343.417,
          510.759
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.0004081632653776756,
      "height": 0,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          353.3795999999999,
          510.759
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "], however, such attention mechanisms",
      "dir": "ltr",
      "width": 150.61916959600012,
      "height": 9.9626,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          353.38,
          510.759
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "are used in conjunction with a recurrent network.",
      "dir": "ltr",
      "width": 195.78501520000003,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          108,
          499.85
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "In this work we propose the Transformer, a model architecture eschewing recurrence and instead",
      "dir": "ltr",
      "width": 395.99721058799986,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          108,
          483.461
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "relying entirely on an attention mechanism to draw global dependencies between input and output.",
      "dir": "ltr",
      "width": 397.73895202079945,
      "height": 9.9626,
      "transform": [
          10.1020764,
          0,
          0,
          9.9626,
          108,
          472.552
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "The Transformer allows for significantly more parallelization and can reach a new state of the art in",
      "dir": "ltr",
      "width": 396.3122280000002,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          107.691,
          461.643
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "translation quality after being trained for as little as twelve hours on eight P100 GPUs.",
      "dir": "ltr",
      "width": 344.357269,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          108,
          450.734
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "",
      "dir": "ltr",
      "width": 0,
      "height": 0,
      "transform": [
          11.9552,
          0,
          0,
          11.9552,
          108,
          419.724
      ],
      "fontName": "g_d0_f2",
      "hasEOL": true
  },
  {
      "str": "2",
      "dir": "ltr",
      "width": 5.9776,
      "height": 11.9552,
      "transform": [
          11.9552,
          0,
          0,
          11.9552,
          108,
          419.724
      ],
      "fontName": "g_d0_f2",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 11.955200000000005,
      "height": 0,
      "transform": [
          11.9552,
          0,
          0,
          11.9552,
          113.9776,
          419.724
      ],
      "fontName": "g_d0_f2",
      "hasEOL": false
  },
  {
      "str": "Background",
      "dir": "ltr",
      "width": 62.896307199999995,
      "height": 11.9552,
      "transform": [
          11.9552,
          0,
          0,
          11.9552,
          125.9328,
          419.724
      ],
      "fontName": "g_d0_f2",
      "hasEOL": false
  },
  {
      "str": "",
      "dir": "ltr",
      "width": 0,
      "height": 0,
      "transform": [
          9.8430488,
          0,
          0,
          9.9626,
          107.691,
          395.041
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU",
      "dir": "ltr",
      "width": 396.3106738343997,
      "height": 9.9626,
      "transform": [
          9.8430488,
          0,
          0,
          9.9626,
          107.691,
          395.041
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "[",
      "dir": "ltr",
      "width": 3.251194884,
      "height": 9.9626,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          108,
          384.132
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "16",
      "dir": "ltr",
      "width": 9.9626,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          111.251,
          384.132
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.0004081632652906703,
      "height": 0,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          121.21360000000001,
          384.132
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "], ByteNet [",
      "dir": "ltr",
      "width": 46.18063603999999,
      "height": 9.9626,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          121.214,
          384.132
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.0003639599999587517,
      "height": 0,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          167.39463604000005,
          384.132
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "18",
      "dir": "ltr",
      "width": 9.9626,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          167.395,
          384.132
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.0004081632652906703,
      "height": 0,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          177.35760000000002,
          384.132
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "] and ConvS2S [",
      "dir": "ltr",
      "width": 64.09637961999998,
      "height": 9.9626,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          177.358,
          384.132
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.0006203799999866533,
      "height": 0,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          241.45437962000003,
          384.132
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "9",
      "dir": "ltr",
      "width": 4.9813,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          241.455,
          384.132
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "], all of which use convolutional neural networks as basic building",
      "dir": "ltr",
      "width": 257.566883588,
      "height": 9.9626,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          246.436,
          384.132
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "block, computing hidden representations in parallel for all input and output positions. In these models,",
      "dir": "ltr",
      "width": 397.2413400759998,
      "height": 9.9626,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          108,
          373.223
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "the number of operations required to relate signals from two arbitrary input or output positions grows",
      "dir": "ltr",
      "width": 396.0013948799994,
      "height": 9.9626,
      "transform": [
          9.763348,
          0,
          0,
          9.9626,
          108,
          362.313
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes",
      "dir": "ltr",
      "width": 395.9992828087997,
      "height": 9.9626,
      "transform": [
          9.7932358,
          0,
          0,
          9.9626,
          108,
          351.404
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "it more difficult to learn dependencies between distant positions [",
      "dir": "ltr",
      "width": 270.1731591240001,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          108,
          340.495
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "12",
      "dir": "ltr",
      "width": 9.9626,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          378.169,
          340.495
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.0003921568628138451,
      "height": 0,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          388.13159999999993,
          340.495
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "]. In the Transformer this is",
      "dir": "ltr",
      "width": 115.86543650400012,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          388.132,
          340.495
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "reduced to a constant number of operations, albeit at the cost of reduced effective resolution due",
      "dir": "ltr",
      "width": 395.9972105879999,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          108,
          329.586
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as",
      "dir": "ltr",
      "width": 395.9972105879997,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          108,
          318.677
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "described in section 3.2.",
      "dir": "ltr",
      "width": 96.56748179999998,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          108,
          307.768
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions",
      "dir": "ltr",
      "width": 395.9995816867997,
      "height": 9.9626,
      "transform": [
          9.8231236,
          0,
          0,
          9.9626,
          108,
          291.379
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "of a single sequence in order to compute a representation of the sequence. Self-attention has been",
      "dir": "ltr",
      "width": 395.9972105880001,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          108,
          280.47
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "used successfully in a variety of tasks including reading comprehension, abstractive summarization,",
      "dir": "ltr",
      "width": 397.2495691835999,
      "height": 9.9626,
      "transform": [
          9.9526374,
          0,
          0,
          9.9626,
          108,
          269.561
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "textual entailment and learning task-independent sentence representations [4, 27, 28, 22].",
      "dir": "ltr",
      "width": 355.116877,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          108,
          258.652
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "End-to-end memory networks are based on a recurrent attention mechanism instead of sequence-",
      "dir": "ltr",
      "width": 397.65359246399987,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          108,
          242.264
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "aligned recurrence and have been shown to perform well on simple-language question answering and",
      "dir": "ltr",
      "width": 395.99499889079954,
      "height": 9.9626,
      "transform": [
          9.7733106,
          0,
          0,
          9.9626,
          108,
          231.355
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "language modeling tasks [34].",
      "dir": "ltr",
      "width": 120.0891804,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          108,
          220.445
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "To the best of our knowledge, however, the Transformer is the first transduction model relying",
      "dir": "ltr",
      "width": 396.3122279999997,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          107.691,
          204.057
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "entirely on self-attention to compute representations of its input and output without using sequence-",
      "dir": "ltr",
      "width": 397.65717899999964,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          108,
          193.148
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate",
      "dir": "ltr",
      "width": 395.9973699895998,
      "height": 9.9626,
      "transform": [
          9.9327122,
          0,
          0,
          9.9626,
          108,
          182.239
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "self-attention and discuss its advantages over models such as [17, 18] and [9].",
      "dir": "ltr",
      "width": 309.3486926000002,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          108,
          171.33
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "",
      "dir": "ltr",
      "width": 0,
      "height": 0,
      "transform": [
          11.9552,
          0,
          0,
          11.9552,
          108,
          140.32000000000002
      ],
      "fontName": "g_d0_f2",
      "hasEOL": true
  },
  {
      "str": "3",
      "dir": "ltr",
      "width": 5.9776,
      "height": 11.9552,
      "transform": [
          11.9552,
          0,
          0,
          11.9552,
          108,
          140.32000000000002
      ],
      "fontName": "g_d0_f2",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 11.955200000000005,
      "height": 0,
      "transform": [
          11.9552,
          0,
          0,
          11.9552,
          113.9776,
          140.32000000000002
      ],
      "fontName": "g_d0_f2",
      "hasEOL": false
  },
  {
      "str": "Model Architecture",
      "dir": "ltr",
      "width": 100.1606656,
      "height": 11.9552,
      "transform": [
          11.9552,
          0,
          0,
          11.9552,
          125.9328,
          140.32000000000002
      ],
      "fontName": "g_d0_f2",
      "hasEOL": false
  },
  {
      "str": "",
      "dir": "ltr",
      "width": 0,
      "height": 0,
      "transform": [
          9.912787,
          0,
          0,
          9.9626,
          108,
          115.636
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "Most competitive neural sequence transduction models have an encoder-decoder structure [",
      "dir": "ltr",
      "width": 362.0843707489998,
      "height": 9.9626,
      "transform": [
          9.912787,
          0,
          0,
          9.9626,
          108,
          115.636
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.0006292509997933848,
      "height": 0,
      "transform": [
          9.912787,
          0,
          0,
          9.9626,
          470.0843707490002,
          115.636
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "5",
      "dir": "ltr",
      "width": 4.9813,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          470.085,
          115.636
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": ",",
      "dir": "ltr",
      "width": 2.47819675,
      "height": 9.9626,
      "transform": [
          9.912787,
          0,
          0,
          9.9626,
          475.066,
          115.636
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 2.4988032500000372,
      "height": 0,
      "transform": [
          9.912787,
          0,
          0,
          9.9626,
          477.54419674999997,
          115.636
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "2",
      "dir": "ltr",
      "width": 4.9813,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          480.043,
          115.636
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 0.0007035175879344883,
      "height": 0,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          485.0243,
          115.636
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": ",",
      "dir": "ltr",
      "width": 2.47819675,
      "height": 9.9626,
      "transform": [
          9.912787,
          0,
          0,
          9.9626,
          485.025,
          115.636
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 2.4988032500000372,
      "height": 0,
      "transform": [
          9.912787,
          0,
          0,
          9.9626,
          487.50319675,
          115.636
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "35",
      "dir": "ltr",
      "width": 9.9626,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          490.002,
          115.636
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "].",
      "dir": "ltr",
      "width": 5.779154821,
      "height": 9.9626,
      "transform": [
          9.912787,
          0,
          0,
          9.9626,
          499.964,
          115.636
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "Here, the encoder maps an input sequence of symbol representations",
      "dir": "ltr",
      "width": 286.625197512,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          108,
          104.727
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 3.3135318509808895,
      "height": 0,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          394.6251975119995,
          104.727
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "(",
      "dir": "ltr",
      "width": 3.87445514,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          398.005,
          104.727
      ],
      "fontName": "g_d0_f11",
      "hasEOL": false
  },
  {
      "str": "x",
      "dir": "ltr",
      "width": 5.6936259,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          401.879,
          104.727
      ],
      "fontName": "g_d0_f8",
      "hasEOL": false
  },
  {
      "str": "1",
      "dir": "ltr",
      "width": 3.9715790999999996,
      "height": 6.9738,
      "transform": [
          6.9738,
          0,
          0,
          6.9738,
          407.57300000000004,
          103.233
      ],
      "fontName": "g_d0_f10",
      "hasEOL": false
  },
  {
      "str": ", ..., x",
      "dir": "ltr",
      "width": 22.849223100000003,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          412.04200000000003,
          104.727
      ],
      "fontName": "g_d0_f8",
      "hasEOL": false
  },
  {
      "str": "n",
      "dir": "ltr",
      "width": 4.92489756,
      "height": 6.9738,
      "transform": [
          6.9738,
          0,
          0,
          6.9738,
          434.894,
          103.233
      ],
      "fontName": "g_d0_f9",
      "hasEOL": false
  },
  {
      "str": ")",
      "dir": "ltr",
      "width": 3.87445514,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          440.317,
          104.727
      ],
      "fontName": "g_d0_f11",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 3.382544859999996,
      "height": 0,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          444.19145514,
          104.727
      ],
      "fontName": "g_d0_f11",
      "hasEOL": false
  },
  {
      "str": "to a sequence",
      "dir": "ltr",
      "width": 56.42876415599995,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          447.574,
          104.727
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "of continuous representations",
      "dir": "ltr",
      "width": 121.96254770400006,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          108,
          93.818
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 3.622992447058753,
      "height": 0,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          229.96254770400006,
          93.818
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "z",
      "dir": "ltr",
      "width": 5.09188486,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          233.658,
          93.818
      ],
      "fontName": "g_d0_f12",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 4.991115140000005,
      "height": 0,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          238.74988485999998,
          93.818
      ],
      "fontName": "g_d0_f12",
      "hasEOL": false
  },
  {
      "str": "= (",
      "dir": "ltr",
      "width": 16.614628019999998,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          243.74099999999999,
          93.818
      ],
      "fontName": "g_d0_f11",
      "hasEOL": false
  },
  {
      "str": "z",
      "dir": "ltr",
      "width": 4.63360526,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          260.354,
          93.818
      ],
      "fontName": "g_d0_f8",
      "hasEOL": false
  },
  {
      "str": "1",
      "dir": "ltr",
      "width": 3.9715790999999996,
      "height": 6.9738,
      "transform": [
          6.9738,
          0,
          0,
          6.9738,
          264.988,
          92.324
      ],
      "fontName": "g_d0_f10",
      "hasEOL": false
  },
  {
      "str": ", ..., z",
      "dir": "ltr",
      "width": 21.789202460000002,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          269.457,
          93.818
      ],
      "fontName": "g_d0_f8",
      "hasEOL": false
  },
  {
      "str": "n",
      "dir": "ltr",
      "width": 4.92489756,
      "height": 6.9738,
      "transform": [
          6.9738,
          0,
          0,
          6.9738,
          291.248,
          92.324
      ],
      "fontName": "g_d0_f9",
      "hasEOL": false
  },
  {
      "str": ")",
      "dir": "ltr",
      "width": 3.87445514,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          296.671,
          93.818
      ],
      "fontName": "g_d0_f11",
      "hasEOL": false
  },
  {
      "str": ".",
      "dir": "ltr",
      "width": 2.540463,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          300.545,
          93.818
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 6.555390799999994,
      "height": 0,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          303.085463,
          93.818
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "Given",
      "dir": "ltr",
      "width": 24.439254060000003,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          309.771961616,
          93.818
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 3.6203767882353515,
      "height": 0,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          334.21121567599994,
          93.818
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "z",
      "dir": "ltr",
      "width": 5.09188486,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          337.904,
          93.818
      ],
      "fontName": "g_d0_f12",
      "hasEOL": false
  },
  {
      "str": ", the decoder then generates an output",
      "dir": "ltr",
      "width": 161.00438308800014,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          342.996,
          93.818
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "sequence",
      "dir": "ltr",
      "width": 37.24318758,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          108,
          82.909
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 2.508639627450962,
      "height": 0,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          145.24318758,
          82.909
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  },
  {
      "str": "(",
      "dir": "ltr",
      "width": 3.87445514,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          147.802,
          82.909
      ],
      "fontName": "g_d0_f11",
      "hasEOL": false
  },
  {
      "str": "y",
      "dir": "ltr",
      "width": 4.88466278,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          151.676,
          82.909
      ],
      "fontName": "g_d0_f8",
      "hasEOL": false
  },
  {
      "str": "1",
      "dir": "ltr",
      "width": 3.9715790999999996,
      "height": 6.9738,
      "transform": [
          6.9738,
          0,
          0,
          6.9738,
          156.56099999999998,
          81.415
      ],
      "fontName": "g_d0_f10",
      "hasEOL": false
  },
  {
      "str": ", ..., y",
      "dir": "ltr",
      "width": 22.040259980000002,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          161.02999999999997,
          82.909
      ],
      "fontName": "g_d0_f8",
      "hasEOL": false
  },
  {
      "str": "m",
      "dir": "ltr",
      "width": 7.06934106,
      "height": 6.9738,
      "transform": [
          6.9738,
          0,
          0,
          6.9738,
          183.07299999999998,
          81.415
      ],
      "fontName": "g_d0_f9",
      "hasEOL": false
  },
  {
      "str": ")",
      "dir": "ltr",
      "width": 3.87445514,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          190.64,
          82.909
      ],
      "fontName": "g_d0_f11",
      "hasEOL": false
  },
  {
      "str": " ",
      "dir": "ltr",
      "width": 2.559544860000017,
      "height": 0,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          194.51445514,
          82.909
      ],
      "fontName": "g_d0_f11",
      "hasEOL": false
  },
  {
      "str": "of symbols one element at a time. At each step the model is auto-regressive",
      "dir": "ltr",
      "width": 306.9285778080001,
      "height": 9.9626,
      "transform": [
          10.161852,
          0,
          0,
          9.9626,
          197.074,
          82.909
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "[10], consuming the previously generated symbols as additional input when generating the next.",
      "dir": "ltr",
      "width": 382.5638399999999,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          108,
          72
      ],
      "fontName": "g_d0_f1",
      "hasEOL": true
  },
  {
      "str": "2",
      "dir": "ltr",
      "width": 4.9813,
      "height": 9.9626,
      "transform": [
          9.9626,
          0,
          0,
          9.9626,
          303.509,
          42.111999999999995
      ],
      "fontName": "g_d0_f1",
      "hasEOL": false
  }
]